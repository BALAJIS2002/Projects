{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVkAb8iQe5s-",
        "outputId": "32287e6a-ee6b-4374-d32a-a8b4993cbd47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12579363.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Epoch 1, Batch 100, Loss: 1.908914761543274\n",
            "Epoch 1, Batch 200, Loss: 1.6881796860694884\n",
            "Epoch 1, Batch 300, Loss: 1.5614552509784698\n",
            "Epoch 1, Batch 400, Loss: 1.476861379146576\n",
            "Epoch 1, Batch 500, Loss: 1.3676432633399964\n",
            "Epoch 1, Batch 600, Loss: 1.2921091383695602\n",
            "Epoch 1, Batch 700, Loss: 1.2211811923980713\n",
            "Epoch 2, Batch 100, Loss: 1.116407887339592\n",
            "Epoch 2, Batch 200, Loss: 1.046716919541359\n",
            "Epoch 2, Batch 300, Loss: 1.0427150011062623\n",
            "Epoch 2, Batch 400, Loss: 0.992351871728897\n",
            "Epoch 2, Batch 500, Loss: 0.9412319147586823\n",
            "Epoch 2, Batch 600, Loss: 0.9406729835271835\n",
            "Epoch 2, Batch 700, Loss: 0.8822331881523132\n",
            "Epoch 3, Batch 100, Loss: 0.8083757004141807\n",
            "Epoch 3, Batch 200, Loss: 0.8033378323912621\n",
            "Epoch 3, Batch 300, Loss: 0.7827082127332687\n",
            "Epoch 3, Batch 400, Loss: 0.7645208638906479\n",
            "Epoch 3, Batch 500, Loss: 0.742219472527504\n",
            "Epoch 3, Batch 600, Loss: 0.7189898347854614\n",
            "Epoch 3, Batch 700, Loss: 0.7046088826656342\n",
            "Epoch 4, Batch 100, Loss: 0.611378935277462\n",
            "Epoch 4, Batch 200, Loss: 0.6537746724486351\n",
            "Epoch 4, Batch 300, Loss: 0.6186280715465545\n",
            "Epoch 4, Batch 400, Loss: 0.6211298882961274\n",
            "Epoch 4, Batch 500, Loss: 0.6411767300963401\n",
            "Epoch 4, Batch 600, Loss: 0.5979952600598335\n",
            "Epoch 4, Batch 700, Loss: 0.5976168578863144\n",
            "Epoch 5, Batch 100, Loss: 0.521113185286522\n",
            "Epoch 5, Batch 200, Loss: 0.524548025727272\n",
            "Epoch 5, Batch 300, Loss: 0.5041129216551781\n",
            "Epoch 5, Batch 400, Loss: 0.5063736316561699\n",
            "Epoch 5, Batch 500, Loss: 0.5216324304044246\n",
            "Epoch 5, Batch 600, Loss: 0.5233652332425117\n",
            "Epoch 5, Batch 700, Loss: 0.5214555439352989\n",
            "Epoch 6, Batch 100, Loss: 0.4488196983933449\n",
            "Epoch 6, Batch 200, Loss: 0.4255881287157536\n",
            "Epoch 6, Batch 300, Loss: 0.42160432785749435\n",
            "Epoch 6, Batch 400, Loss: 0.4433359789848328\n",
            "Epoch 6, Batch 500, Loss: 0.4390971650183201\n",
            "Epoch 6, Batch 600, Loss: 0.4283155235648155\n",
            "Epoch 6, Batch 700, Loss: 0.43673511266708376\n",
            "Epoch 7, Batch 100, Loss: 0.36133328452706337\n",
            "Epoch 7, Batch 200, Loss: 0.34724424466490744\n",
            "Epoch 7, Batch 300, Loss: 0.3652869862318039\n",
            "Epoch 7, Batch 400, Loss: 0.36500991180539133\n",
            "Epoch 7, Batch 500, Loss: 0.35579395458102225\n",
            "Epoch 7, Batch 600, Loss: 0.3598814237862825\n",
            "Epoch 7, Batch 700, Loss: 0.38813642770051954\n",
            "Epoch 8, Batch 100, Loss: 0.2692239771038294\n",
            "Epoch 8, Batch 200, Loss: 0.3035850232839584\n",
            "Epoch 8, Batch 300, Loss: 0.30351422771811487\n",
            "Epoch 8, Batch 400, Loss: 0.3305297911912203\n",
            "Epoch 8, Batch 500, Loss: 0.3294758531451225\n",
            "Epoch 8, Batch 600, Loss: 0.30167576342821123\n",
            "Epoch 8, Batch 700, Loss: 0.3196684730052948\n",
            "Epoch 9, Batch 100, Loss: 0.23227898947894574\n",
            "Epoch 9, Batch 200, Loss: 0.25569826044142246\n",
            "Epoch 9, Batch 300, Loss: 0.2733127908408642\n",
            "Epoch 9, Batch 400, Loss: 0.25649477064609527\n",
            "Epoch 9, Batch 500, Loss: 0.2675809891521931\n",
            "Epoch 9, Batch 600, Loss: 0.27199369117617606\n",
            "Epoch 9, Batch 700, Loss: 0.26200351387262344\n",
            "Epoch 10, Batch 100, Loss: 0.19466378945857288\n",
            "Epoch 10, Batch 200, Loss: 0.21576873287558557\n",
            "Epoch 10, Batch 300, Loss: 0.21474857572466136\n",
            "Epoch 10, Batch 400, Loss: 0.21886667810380458\n",
            "Epoch 10, Batch 500, Loss: 0.24314180098474025\n",
            "Epoch 10, Batch 600, Loss: 0.24594365328550338\n",
            "Epoch 10, Batch 700, Loss: 0.22596016086637974\n",
            "Accuracy of the model on the 10000 test images: 83.75%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# CIFAR-10 has 10 classes\n",
        "num_classes = 10\n",
        "\n",
        "# Image Preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalization\n",
        "])\n",
        "\n",
        "# Download and load the CIFAR-10 data\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform)\n",
        "\n",
        "# Data Loader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define a GoogLeNet model for CIFAR-10\n",
        "class GoogLeNetCIFAR10(models.GoogLeNet):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(GoogLeNetCIFAR10, self).__init__(num_classes=num_classes, aux_logits=False, init_weights=True)\n",
        "        # Redefine the first convolutional layer to accept CIFAR-10's 32x32 pixel images\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Follow the forward pass of the GoogLeNet model\n",
        "        return super(GoogLeNetCIFAR10, self).forward(x)\n",
        "\n",
        "# Instantiate the model and transfer it to the GPU\n",
        "model = GoogLeNetCIFAR10(num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Function to train the model\n",
        "def train(model, criterion, optimizer, train_loader, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "            # Transfer inputs and labels to the GPU\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 99:\n",
        "                print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "                running_loss = 0.0\n",
        "\n",
        "# Function to test the model\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            # Transfer images and labels to the GPU\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Start training\n",
        "train(model, criterion, optimizer, train_loader, epochs=10)\n",
        "\n",
        "# Test the model\n",
        "accuracy = test(model, test_loader)\n",
        "print(f'Accuracy of the model on the 10000 test images: {accuracy}%')\n"
      ]
    }
  ]
}